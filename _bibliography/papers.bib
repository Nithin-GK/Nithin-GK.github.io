@inproceedings{nair2023unite,
  title={Unite and Conquer: Plug \& Play Multi-Modal Synthesis Using Diffusion Models},
  author={Nair, Nithin Gopalakrishnan and Bandara, Wele Gedara Chaminda and Patel, Vishal M},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6070--6079},
  year={2023},
  pdf={https://openaccess.thecvf.com/content/CVPR2023/papers/Nair_Unite_and_Conquer_Plug__Play_Multi-Modal_Synthesis_Using_Diffusion_CVPR_2023_paper.pdf}
  abstract={Generating photos satisfying multiple constraints finds
broad utility in the content creation industry. A key hurdle to accomplishing this task is the need for paired data
consisting of all modalities (i.e., constraints) and their corresponding output. Moreover, existing methods need retraining using paired data across all modalities to introduce a new condition. This paper proposes a solution to this
problem based on denoising diffusion probabilistic models
(DDPMs). Our motivation for choosing diffusion models
over other generative models comes from the flexible internal structure of diffusion models. Since each sampling
step in the DDPM follows a Gaussian distribution, we show
that there exists a closed-form solution for generating an
image given various constraints. Our method can unite
multiple diffusion models trained on multiple sub-tasks and
conquer the combined task through our proposed sampling
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore. 6070
strategy. We also introduce a novel reliability parameter that allows using different off-the-shelf diffusion models trained across various datasets during sampling time
alone to guide it to the desired outcome satisfying multiple constraints. We perform experiments on various standard multimodal tasks to demonstrate the effectiveness of
our approach. More details can be found at: https://nithingk.github.io/projectpages/Multidiff}
  preview={multi.png}
}


@inproceedings{nair2023t2v,
  title={T2V-DDPM: Thermal to Visible Face Translation using Denoising Diffusion Probabilistic Models},
  author={Nair, Nithin Gopalakrishnan and Patel, Vishal M},
  booktitle={2023 IEEE 17th International Conference on Automatic Face and Gesture Recognition (FG)},
  pages={1--7},
  year={2023},
  organization={IEEE}
}


@article{mei2022bi,
  title={Bi-Noising Diffusion: Towards Conditional Diffusion Models with Generative Restoration Priors},
  author={Mei, Kangfu and Nair, Nithin Gopalakrishnan and Patel, Vishal M},
  journal={arXiv preprint arXiv:2212.07352},
  year={2022}
}

@InProceedings{Nair_2023_WACV,
    author    = {Nair, Nithin Gopalakrishnan and Mei, Kangfu and Patel, Vishal M.},
    title     = {AT-DDPM: Restoring Faces Degraded by Atmospheric Turbulence Using Denoising Diffusion Probabilistic Models},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2023},
    pages     = {3434-3443}
}

@article{ranasinghe2023diffuse,
  title={Diffuse-Denoise-Count: Accurate Crowd-Counting with Diffusion Models},
  author={Ranasinghe, Yasiru and Nair, Nithin Gopalakrishnan and Bandara, Wele Gedara Chaminda and Patel, Vishal M},
  journal={arXiv preprint arXiv:2303.12790},
  year={2023}
}

@article{bandara2022ddpm,
  title={DDPM-CD: Remote Sensing Change Detection using Denoising Diffusion Probabilistic Models},
  author={Bandara, Wele Gedara Chaminda and Nair, Nithin Gopalakrishnan and Patel, Vishal M},
  journal={arXiv preprint arXiv:2206.11892},
  year={2022}
}

@article{perera2023sar,
  title={Sar despeckling using a denoising diffusion probabilistic model},
  author={Perera, Malsha V and Nair, Nithin Gopalakrishnan and Bandara, Wele Gedara Chaminda and Patel, Vishal M},
  journal={IEEE Geoscience and Remote Sensing Letters},
  year={2023},
  publisher={IEEE}
}


@INPROCEEDINGS{9897969,
  author={Gopalakrishnan Nair, Nithin and Mei, Kangfu and Patel, Vishal M.},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)}, 
  title={A Comparison of Different Atmospheric Turbulence Simulation Methods for Image Restoration}, 
  year={2022},
  volume={},
  number={},
  pages={3386-3390},
  doi={10.1109/ICIP46576.2022.9897969}}


@article{mohan2021deep,
  title={Deep dynamic scene deblurring for unconstrained dual-lens cameras},
  author={Mohan, MR Mahesh and Nithin, GK and Rajagopalan, AN},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={4479--4491},
  year={2021},
  publisher={IEEE}
}

@INPROCEEDINGS{9897543,
  author={Gopalakrishnan Nair, Nithin and Yasarla, Rajeev and Patel, Vishal M.},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)}, 
  title={NBD-GAP: Non-Blind Image Deblurring without Clean Target Images}, 
  year={2022},
  volume={},
  number={},
  pages={3431-3435},
  doi={10.1109/ICIP46576.2022.9897543}}

@INPROCEEDINGS{9897543,
  author={Gopalakrishnan Nair, Nithin and Yasarla, Rajeev and Patel, Vishal M.},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)}, 
  title={NBD-GAP: Non-Blind Image Deblurring without Clean Target Images}, 
  year={2022},
  volume={},
  number={},
  pages={3431-3435},
  doi={10.1109/ICIP46576.2022.9897543}}